{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115fbf93-4264-402a-9234-f6a12e0bcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, f1_score, r2_score\n",
    "from tkinter import filedialog\n",
    "from tkinter import Tk\n",
    "from math import sqrt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a747f68-f1dc-4cac-8a3e-5b3fe37ec212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load images from a directory\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a525659f-e724-42fb-a86e-97a0943f8f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the root directory of your dataset\n",
    "root_dir = \"C:\\\\Users\\\\celsi\\\\Downloads\\\\archive\"\n",
    "\n",
    "# Define the paths for damaged and intact images\n",
    "damaged_side_dir = os.path.join(root_dir, 'damaged/side/')\n",
    "damaged_top_dir = os.path.join(root_dir, 'damaged/top/')\n",
    "intact_side_dir = os.path.join(root_dir, 'intact/side/')\n",
    "intact_top_dir = os.path.join(root_dir, 'intact/top/')\n",
    "\n",
    "# Load images from each directory\n",
    "damaged_side_images = load_images_from_folder(damaged_side_dir)\n",
    "damaged_top_images = load_images_from_folder(damaged_top_dir)\n",
    "intact_side_images = load_images_from_folder(intact_side_dir)\n",
    "intact_top_images = load_images_from_folder(intact_top_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e35198-bf31-4208-aa1e-2ade970cc279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for RF algorithm: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions of the images in your dataset\n",
    "width, height = intact_top_images[0].shape[1], intact_top_images[0].shape[0]\n",
    "\n",
    "# Create labels for the images\n",
    "damaged_labels = ['damaged'] * (len(damaged_side_images) + len(damaged_top_images))\n",
    "intact_labels = ['intact'] * (len(intact_side_images) + len(intact_top_images))\n",
    "\n",
    "# Concatenate damaged and intact images and labels\n",
    "all_images = damaged_side_images + damaged_top_images + intact_side_images + intact_top_images\n",
    "all_labels = damaged_labels + intact_labels\n",
    "\n",
    "# Convert images to numpy array\n",
    "all_images = np.array(all_images)\n",
    "\n",
    "# Flatten the images\n",
    "all_images_flattened = all_images.reshape(all_images.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(all_images_flattened, all_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val) \n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred_encoded = model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val_encoded, y_val_pred_encoded)\n",
    "print(f\"Validation Accuracy for RF algorithm: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2659e9d-667c-4d43-aa35-4d9d6fa66e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-squared: 1.0\n",
      "Training RMSE: 0.0\n",
      "Testing R-squared: 0.5997498436522826\n",
      "Testing RMSE: 0.31622776601683794\n",
      "F1 Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Evaluate R-squared and RMSE for training set\n",
    "y_train_pred_encoded = model.predict(X_train)\n",
    "r2_train = r2_score(y_train_encoded, y_train_pred_encoded)\n",
    "rmse_train = sqrt(mean_squared_error(y_train_encoded, y_train_pred_encoded))\n",
    "print(f\"Training R-squared: {r2_train}\")\n",
    "print(f\"Training RMSE: {rmse_train}\")\n",
    "\n",
    "# Evaluate R-squared and RMSE for testing set\n",
    "r2_test = r2_score(y_val_encoded, y_val_pred_encoded)\n",
    "rmse_test = sqrt(mean_squared_error(y_val_encoded, y_val_pred_encoded))\n",
    "print(f\"Testing R-squared: {r2_test}\")\n",
    "print(f\"Testing RMSE: {rmse_test}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_val_encoded, y_val_pred_encoded, average='weighted')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bda3451-bfc8-4200-9497-dac61a268524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path =\"C:\\\\Users\\\\celsi\\\\Downloads\\\\archive\\\\intact\\\\side\\\\0529291161632_side.png\"\n",
    "\n",
    "# Load the user-uploaded image\n",
    "user_image = cv2.imread(image_path)\n",
    "if user_image is None:\n",
    "    print(\"Error loading the image. Exiting.\")\n",
    "else:\n",
    "    # Resize the image to match the model input dimensions\n",
    "    resized_image = cv2.resize(user_image, (width, height))\n",
    "\n",
    "    # Preprocess the image (if needed)\n",
    "    preprocessed_image = resized_image  # Placeholder for any preprocessing steps\n",
    "\n",
    "    # Predict the class label\n",
    "    prediction = model.predict(preprocessed_image.reshape(1, -1))\n",
    "\n",
    " # Define colors for bounding boxes\n",
    "    if prediction[0] == 1:\n",
    "        color = (0, 255, 0)  # Green for intact\n",
    "        label = \"Intact\"\n",
    "    else:\n",
    "        color = (0, 0, 255)  # Red for damaged\n",
    "        label = \"Damaged\"\n",
    "    \n",
    "    # Calculate the bounding box coordinates (assuming the package is in the center of the image)\n",
    "    box_x1, box_y1 = int(width * 0.25), int(height * 0.25)  # Top-left corner\n",
    "    box_x2, box_y2 = int(width * 0.75), int(height * 0.75)  # Bottom-right corner\n",
    "\n",
    "    # Draw a bounding box around the object in the image\n",
    "    cv2.rectangle(resized_image, (box_x1, box_y1), (box_x2, box_y2), color, thickness=2)\n",
    "    \n",
    "    # Add label text\n",
    "    cv2.putText(resized_image, label, (box_x1, box_y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    \n",
    "try:\n",
    "    # Display the image with prediction\n",
    "    cv2.imshow(\"Prediction Result\", resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during image display:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e324e4d-ddd5-4439-b790-338e5ca9295d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Preprocess the frame (resize, normalize, etc.)\n",
    "    frame_resized = cv2.resize(frame, (width, height))  # Set width and height according to your dataset dimensions\n",
    "    frame_flattened = frame_resized.reshape(1, -1)\n",
    "\n",
    "    # Use the trained model to predict\n",
    "    prediction = model.predict(frame_flattened)\n",
    "\n",
    "    # Draw bounding box and text based on prediction\n",
    "    if prediction == 'intact':\n",
    "        # Draw a bounding box with green color around the detected object\n",
    "        cv2.rectangle(frame, (50, 50), (frame.shape[1] - 50, frame.shape[0] - 50), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'Intact', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    elif prediction == 'damaged':\n",
    "        # Draw a bounding box with red color around the detected object\n",
    "        cv2.rectangle(frame, (50, 50), (frame.shape[1] - 50, frame.shape[0] - 50), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, 'Damaged', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    else:\n",
    "        # Draw a bounding box with yellow color around the detected object\n",
    "        cv2.rectangle(frame, (50, 50), (frame.shape[1] - 50, frame.shape[0] - 50), (0, 255, 255), 2)\n",
    "        cv2.putText(frame, 'Different Product', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Webcam Output', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f34e5-f320-4bbc-b447-8c8c19bbb071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a100816-312a-4f9d-b804-6abf9186efde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb9c63-a1e0-4c3a-a0e2-71929ace2453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
